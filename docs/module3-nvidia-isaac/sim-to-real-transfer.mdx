# Sim-to-Real Transfer

The sim-to-real gap is the performance difference between simulated and real robots. This section covers techniques to minimize this gap and successfully deploy AI systems from Isaac Sim to physical hardware.

## Understanding the Sim-to-Real Gap

Simulations are **approximations** of reality. Common discrepancies include:

### 1. Physics Modeling Errors

**Simulation**: Perfect rigid bodies, idealized contacts
**Reality**: Compliance, backlash, flex, unmodeled dynamics

**Example**: Simulated robot joints have zero backlash. Real gearboxes have 0.5-2° play, causing oscillations.

### 2. Sensor Imperfections

**Simulation**: Perfect measurements with Gaussian noise
**Reality**: Complex noise patterns, systematic biases, temperature drift

**Example**: Simulated camera has uniform Gaussian noise. Real cameras have hot pixels, lens distortion, motion blur, auto-exposure artifacts.

### 3. Actuator Limitations

**Simulation**: Instantaneous torque response
**Reality**: Motor dynamics, current limits, voltage sag, thermal effects

**Example**: Simulated motor reaches 100 N·m instantly. Real motor has 50ms rise time and derates at 80°C.

### 4. Environmental Variability

**Simulation**: Controlled, static environment
**Reality**: Lighting changes, vibrations, temperature variations, unexpected obstacles

**Example**: Simulated floor has µ=0.8. Real floor varies from µ=0.5 (dust) to µ=1.2 (grippy) across surface.

## Quantifying the Gap

### Benchmark Tests

Measure performance difference quantitatively:

| Test | Simulation | Real Robot | Gap |
|------|------------|------------|-----|
| **Walking speed** | 1.0 m/s | 0.7 m/s | 30% slower |
| **Balance duration** | 60 s | 15 s | 4x worse |
| **Grasp success** | 95% | 65% | 30% drop |
| **Navigation accuracy** | ±5 cm | ±15 cm | 3x error |

**Typical sim-to-real gap**: 20-50% performance degradation without mitigation.

## Bridging the Gap: Core Strategies

### 1. System Identification

**Measure real robot parameters** and update simulation:

**Mass and Inertia**:
```python
# Weigh each link
real_mass = {'torso': 22.3, 'thigh_left': 3.8, ...}  # Actual measurements

# Update URDF
for link_name, mass in real_mass.items():
    link = urdf.find(f"./link[@name='{link_name}']/inertial/mass")
    link.set('value', str(mass))
```

**Joint Friction**:
```python
# Measure: apply constant torque, measure steady-state velocity
measured_friction = backdriving_test(joint='knee', torques=[1, 2, 5, 10])

# Fit model
friction_model = fit_coulomb_viscous(measured_friction)
# friction = c_static*sign(vel) + c_viscous*vel

# Update simulation
joint.friction = friction_model.c_static
joint.damping = friction_model.c_viscous
```

**Contact Parameters**:
```python
# Drop test: measure bounce height
drop_height = 0.5  # meters
bounce_height = 0.1  # meters

# Compute coefficient of restitution
e = sqrt(bounce_height / drop_height)  # e = 0.447

# Update simulation
contact.restitution = e
```

### 2. Domain Randomization

**Vary simulation parameters during training** to create robust policies[^1]:

```python
class DomainRandomization:
    def randomize_dynamics(self):
        # Mass randomization (±20%)
        for link in self.robot.links:
            link.mass *= np.random.uniform(0.8, 1.2)

        # Friction randomization
        self.ground_friction = np.random.uniform(0.4, 1.2)

        # Motor strength randomization (±15%)
        self.motor_gains *= np.random.uniform(0.85, 1.15)

    def randomize_sensors(self):
        # Camera noise
        self.camera_noise_std = np.random.uniform(0.005, 0.02)

        # IMU bias drift
        self.imu_bias += np.random.normal(0, 0.001, size=6)

        # Latency randomization (0-50ms)
        self.action_delay = np.random.randint(0, 5)  # timesteps

    def randomize_environment(self):
        # Lighting randomization
        self.light_intensity = np.random.uniform(500, 3000)
        self.light_color = np.random.uniform([0.8, 0.8, 0.8], [1.0, 1.0, 1.0])

        # Ground texture randomization
        self.ground_texture = np.random.choice(textures_library)
```

**Training with randomization**:
```python
for episode in training:
    env.randomize_dynamics()
    env.randomize_sensors()
    env.randomize_environment()

    # Train policy on randomized environment
    policy.update(...)

# Policy learns to be robust to variations
```

**Result**: Policy trained with randomization generalizes 2-3x better to real robot than fixed parameters.

### 3. Progressive Sim-to-Real

**Gradual transition** from simulation to reality:

**Stage 1**: Pure simulation
- Train initial policy in Isaac Sim
- Achieve good performance (e.g., walking 1.0 m/s)

**Stage 2**: Simulation with realistic parameters
- Update sim with system ID measurements
- Add domain randomization
- Retrain policy

**Stage 3**: Hardware-in-the-loop (HIL)
- Run simulation, but use real sensor data
- Test perception pipeline on real images
- Validate sensor processing before full deployment

**Stage 4**: Real robot, constrained
- Deploy to real robot with safety limits
- Low speed (0.3 m/s), soft surfaces
- Collect real-world data

**Stage 5**: Fine-tuning on real data
- Use real-world rollouts to fine-tune policy
- Mix sim and real data (10% real, 90% sim)
- Gradually increase real data proportion

**Stage 6**: Full deployment
- Unconstrained real-world operation
- Continuous learning from experience

### 4. Simulation Fidelity Tuning

**Match simulation to reality**, not reality to perfection:

**Visual Realism** (for vision tasks):
```python
# Use realistic Isaac Sim rendering
camera.enable_motion_blur = True
camera.enable_auto_exposure = True
camera.chromatic_aberration = 0.02
camera.lens_distortion_k1 = -0.2

# Add realistic post-processing
image = add_bloom(image, intensity=0.1)
image = add_vignette(image, amount=0.3)
image = add_compression_artifacts(image, jpeg_quality=85)
```

**Physics Accuracy** (for contact-rich tasks):
```python
# Higher physics fidelity for manipulation
physics_params.solver_iterations = 100  # vs. 50 default
physics_params.contact_tolerance = 0.001  # tighter tolerance
physics_params.enable_stabilization = True
```

**Sensor Realism**:
```python
# IMU noise matching MPU6050 datasheet
imu.accel_noise_density = 400e-6  # µg/√Hz
imu.gyro_noise_density = 0.01  # °/s/√Hz
imu.accel_bias_stability = 0.05  # mg
imu.gyro_bias_stability = 10  # °/hr

# Depth camera characteristics (Intel RealSense D435i)
depth_camera.min_range = 0.3  # meters
depth_camera.max_range = 10.0
depth_camera.noise_model = "quadratic"  # σ = a + b*d²
depth_camera.noise_params = [0.002, 0.0019]
```

### 5. Adaptive Controllers

**Controllers that adapt to reality**:

**Residual Reinforcement Learning**[^2]:
```python
# Combine classical controller with learned residual
def control(observation):
    # Classical PID controller (model-based)
    u_pid = pid_controller(observation)

    # Learned residual (compensates for modeling errors)
    u_residual = learned_policy(observation)

    # Total control
    u_total = u_pid + u_residual
    return u_total
```

**Online Adaptation**:
```python
# Adapt policy based on real-world performance
class AdaptivePolicy:
    def __init__(self):
        self.base_policy = load_trained_policy()
        self.adaptation_layer = nn.Linear(state_dim, action_dim)

    def forward(self, obs, context):
        # Base policy from simulation
        action_base = self.base_policy(obs)

        # Adaptation based on recent performance
        action_adapt = self.adaptation_layer(context)

        return action_base + 0.1 * action_adapt

    def update_adaptation(self, real_world_rollouts):
        # Fast adaptation to real robot (meta-learning)
        for trajectory in real_world_rollouts:
            loss = compute_loss(trajectory)
            loss.backward()
            optimizer.step()  # Only update adaptation_layer
```

## Validation Protocol

### Pre-Deployment Checklist

**1. Simulation Validation**
- [ ] Policy achieves target performance in sim (e.g., walking 1.0 m/s)
- [ ] Robust to domain randomization (success rate >80% across variations)
- [ ] Tested in diverse simulated scenarios

**2. Parameter Validation**
- [ ] Mass/inertia match real robot (within 10%)
- [ ] Joint friction measured and sim updated
- [ ] Contact parameters validated with drop tests

**3. Sensor Validation**
- [ ] Simulated sensor data visually similar to real
- [ ] Noise characteristics match (compute statistics on real data)
- [ ] Latencies measured and incorporated

**4. Safety Validation**
- [ ] Emergency stop functional
- [ ] Soft limits on joint torques
- [ ] Tethered power supply (for initial tests)
- [ ] Crash mats / soft landing surfaces

### Deployment Steps

**Step 1**: Static test
- Power on robot, hold in stand
- Send zero torques, verify no movement
- Send small test commands, verify expected response

**Step 2**: Suspended test
- Suspend robot (e.g., with gantry)
- Run walking controller in air
- Verify gait pattern looks correct

**Step 3**: Supported test
- Robot stands on ground, held by human or support rig
- Enable controller, verify balancing torques
- Gradually reduce support

**Step 4**: Constrained test
- Robot operates independently
- Confined space (padded room)
- Low-speed commands only (0.3 m/s max)

**Step 5**: Open test
- Full autonomy
- Normal operating speed
- Monitor performance, collect data for analysis

## Case Studies

### Case Study 1: Boston Dynamics Atlas

**Sim-to-Real Approach**:
1. Physics simulation for initial controller design
2. Extensive system ID (mass, inertia, actuator dynamics)
3. Simplified terrain in sim matched to test environment
4. Iterative: sim → test → update sim → repeat

**Result**: Parkour capabilities developed primarily in simulation, transferred to real robot with minimal tuning.

### Case Study 2: Learning Dexterous Manipulation (OpenAI)

**Sim-to-Real Approach**[^3]:
1. Train in simulation with aggressive domain randomization
2. Randomize: object size, mass, friction, finger friction, gravity, action delays
3. 100 years of simulated experience (parallelized)
4. Direct transfer to real Rubik's cube solving

**Result**: Sim-trained policy solved Rubik's cube on real hardware with 60% success rate, no fine-tuning.

### Case Study 3: ANYmal Quadruped

**Sim-to-Real Approach**:
1. Teacher-student learning: Teacher has access to privileged info in sim (exact terrain, contact forces)
2. Student learns to imitate teacher using only real sensors
3. Student deployed to real robot

**Result**: Robust locomotion on diverse terrains with same policy.

## Measuring Success

### Quantitative Metrics

**Performance parity**:
```
Parity = (Real Performance / Sim Performance) * 100%
```
- Goal: above 80% parity
- Under 50% parity indicates significant gap

**Robustness**:
```
Robustness = (Success Rate on Perturbations) / (Success Rate Nominal)
```
- Goal: above 0.7 robustness
- Test perturbations: push robot, irregular surfaces, varying payloads

**Sample efficiency** (for online learning):
```
Sample Efficiency = (Episodes to Learn in Sim) / (Episodes to Learn in Real)
```
- Goal: 10x fewer real episodes than sim
- Indicates good transfer

### Qualitative Assessment

- Visual smoothness (no jitter or oscillations)
- Stability under disturbances
- Generalization to novel scenarios
- Long-term reliability (hours of operation)

## Common Pitfalls

**Pitfall 1**: Over-optimizing for simulation
- **Problem**: Policy exploits sim quirks
- **Solution**: Diverse scenarios, domain randomization

**Pitfall 2**: Insufficient safety testing
- **Problem**: Policy causes damage on first real test
- **Solution**: Progressive deployment, soft constraints

**Pitfall 3**: Ignoring systematic errors
- **Problem**: Policy assumes unbiased sensors
- **Solution**: Model sensor biases, recalibrate regularly

**Pitfall 4**: No real-world data collection
- **Problem**: Cannot validate sim assumptions
- **Solution**: Collect real data early, iterate sim-real loop

## Summary

Sim-to-real transfer requires:

✅ **System identification** to match sim parameters to reality
✅ **Domain randomization** to create robust policies
✅ **Progressive deployment** from sim to real
✅ **Realistic simulation** (sensors, physics, rendering)
✅ **Adaptive controllers** that compensate for errors
✅ **Rigorous validation** before full deployment

With careful engineering, sim-to-real gaps of 20-40% are achievable for complex humanoid tasks.

## Next Steps

You've completed Module 3! You now understand the full NVIDIA Isaac ecosystem. Continue to **Module 4: Vision-Language-Action Integration** to add cognitive planning with LLMs!

---

## References

[^1]: Tobin, J., et al. (2017). Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World. *IEEE/RSJ IROS*, 23-30.

[^2]: Johannink, T., et al. (2019). Residual Reinforcement Learning for Robot Control. *ICRA 2019*, 6023-6029.

[^3]: OpenAI, et al. (2019). Solving Rubik's Cube with a Robot Hand. *arXiv preprint arXiv:1910.07113*.

[^4]: Lee, J., et al. (2020). Learning Quadrupedal Locomotion over Challenging Terrain. *Science Robotics*, 5(47), eabc5986.
